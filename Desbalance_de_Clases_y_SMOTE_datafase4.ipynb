{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1QE3JnEHrTgYRxiAxP2ooKFx8ZL4T-D-W",
      "authorship_tag": "ABX9TyNnLCElqMc4KlOkdQlrH8eD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FranciscoChavezData/Data-Analytics-IDS-Fase4/blob/main/Desbalance_de_Clases_y_SMOTE_datafase4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Paso 1: Configuración del Entorno (Google Colab)\n",
        "\n",
        "**1.1 Importación de Librerías**"
      ],
      "metadata": {
        "id": "lpWxSfZx00vk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AOkZaoFfzMJq"
      },
      "outputs": [],
      "source": [
        "# BITÁCORA: PASO 1.1 - Importación de Librerías Necesarias\n",
        "# Pandas: Para manejar DataFrames (tablas).\n",
        "# Scikit-learn: Librería principal para Machine Learning (IA).\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from IPython.display import display\n",
        "from google.colab import drive # Necesario para montar tu Drive"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.2 Montar Google Drive**"
      ],
      "metadata": {
        "id": "-26a8-Vr1hS5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# BITÁCORA: PASO 1.2  - Montar Google Drive\n",
        "# Ejecuta esta celda y sigue el enlace para dar permiso a Colab de acceder a tu Drive.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "print(\"Google Drive montado con éxito. Puedes encontrar tus archivos en la carpeta '/content/drive/MyDrive'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJX3G_YPLKPN",
        "outputId": "d25954b5-00c4-466d-dc4e-4af5b7aaac0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Google Drive montado con éxito. Puedes encontrar tus archivos en la carpeta '/content/drive/MyDrive'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ESTE PASO REEMPLAZA LOS PASOS 2, 3 Y 4 FRAGMENTADOS.**\n",
        "En este nuevo paso cargamos el Código Monolítico (El Nuevo Paso 2/3/4)"
      ],
      "metadata": {
        "id": "9mFu7mbK2EQb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# CÓDIGO MONOLÍTICO FINAL (Carga, Limpieza, Split, Escala y SMOTE)\n",
        "# ESTE CÓDIGO REEMPLAZA LOS PASOS 2, 3 Y 4 FRAGMENTADOS.\n",
        "# =========================================================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from IPython.display import display\n",
        "\n",
        "print(\"---------------------------------------------------------\")\n",
        "print(\"INICIO DEL PROCESO MONOLÍTICO: Limpieza, Escalado y SMOTE.\")\n",
        "print(\"---------------------------------------------------------\")\n",
        "\n",
        "# --- 1. CARGA DE DATOS ---\n",
        "# ASEGÚRATE DE QUE ESTA RUTA SEA CORRECTA\n",
        "file_name = '/content/drive/MyDrive/Colab Notebooks/DataAnalytics/iotsim-hydraulic-system-2.csv'\n",
        "print(f\"1. Cargando archivo: {file_name}...\")\n",
        "\n",
        "# Usamos low_memory=False para manejar el archivo grande de 2.1M de registros.\n",
        "df = pd.read_csv(file_name, low_memory=False)\n",
        "print(f\"✅ Archivo cargado con éxito. Total de filas: {df.shape[0]}\")\n",
        "\n",
        "# Definición de X (features) y y (target/etiqueta)\n",
        "X = df.drop('label', axis=1).copy()\n",
        "y = df['label'].copy()\n",
        "\n",
        "# --- 2. ENCODIFICACIÓN DE LA ETIQUETA 'y' ---\n",
        "# Convertimos todas las etiquetas (Mirai, Benign, etc.) a números (0, 1, 2...)\n",
        "print(\"\\n2. Codificación de etiquetas (LabelEncoder)...\")\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "y = pd.Series(y_encoded, index=y.index, name='label_encoded')\n",
        "\n",
        "# --- 3. LIMPIEZA Y CONVERSIÓN DE CARACTERÍSTICAS 'X' ---\n",
        "print(\"3. Limpieza y Procesamiento de X...\")\n",
        "# Columnas que históricamente causan problemas o son redundantes\n",
        "columns_to_drop_manual = [\n",
        "    'frame.time', 'ip.dst', 'ip.src', 'eth.src', 'eth.dst', 'ip.checksum',\n",
        "    'tcp.options', 'tcp.pdu.size', 'udp.srcport', 'udp.dstport', 'tcp.checksum',\n",
        "    'tcp.flags', 'ip.flags', 'ip.tos', 'frame.protocols'\n",
        "]\n",
        "columns_to_drop_existing = [col for col in X.columns if col in columns_to_drop_manual]\n",
        "X_processed = X.drop(columns=columns_to_drop_existing, axis=1, errors='ignore').copy()\n",
        "\n",
        "# Convertir columnas de texto restantes (si las hay) a numérico (NaN si falla)\n",
        "for col in X_processed.columns:\n",
        "    if X_processed[col].dtype == 'object':\n",
        "        X_processed[col] = pd.to_numeric(X_processed[col], errors='coerce')\n",
        "\n",
        "# Imputar/Rellenar valores faltantes (NaN) con la media\n",
        "X_processed = X_processed.fillna(X_processed.mean(numeric_only=True))\n",
        "print(\"✅ Limpieza y conversión completada.\")\n",
        "\n",
        "\n",
        "# --- 4. DIVISIÓN (SPLIT) Y ESCALADO (SCALE) ---\n",
        "print(\"\\n4. División y Escalado de Datos...\")\n",
        "# Split con stratify para mantener la proporción de clases en train y test\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_processed, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Escalado con StandardScaler (solo en columnas numéricas)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train.values)\n",
        "X_test_scaled = scaler.transform(X_test.values)\n",
        "\n",
        "X_train = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
        "X_test = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
        "print(\"✅ Split y Escalado completados.\")\n",
        "\n",
        "# --- 5. APLICANDO SMOTE (BALANCEO) ---\n",
        "print(\"\\n5. Aplicando SMOTE (Balanceo) para la clase minoritaria 'Benign'...\")\n",
        "# SMOTE solo se aplica al conjunto de entrenamiento\n",
        "smote = SMOTE(random_state=42, n_jobs=-1)\n",
        "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "print(\"✅ SMOTE aplicado con éxito.\")\n",
        "print(\"\\nDistribución de Clases DESPUÉS del balanceo (y_train_res):\")\n",
        "# Mostramos el balanceo. Las clases minoritarias deben tener el mismo conteo que la clase mayoritaria.\n",
        "display(y_train_res.value_counts())\n",
        "\n",
        "print(\"\\n---------------------------------------------------------\")\n",
        "print(\"¡PROCESAMIENTO FINALIZADO! Listo para el Paso 5: Entrenamiento del Modelo.\")\n",
        "print(\"---------------------------------------------------------\")"
      ],
      "metadata": {
        "id": "wnZkgIoK7xfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PASO 5: ENTRENAMIENTO Y EVALUACIÓN DEL MODELO RANDOM FOREST**"
      ],
      "metadata": {
        "id": "eJM0kCw07x5r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# BITÁCORA: PASO 5.1 - Definición y Entrenamiento del Modelo (Random Forest Classifier)\n",
        "# Random Forest es un algoritmo de IA robusto para clasificación en seguridad IoT.\n",
        "# class_weight='balanced' le da más peso a los ataques (clase minoritaria).\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
        "\n",
        "# **TEMPORARY FIX:** Drop 'tcp.flags' if it still exists in X_train and X_test\n",
        "# It's recommended to handle this in the data processing step (Paso 4).\n",
        "if 'tcp.flags' in X_train.columns:\n",
        "    X_train = X_train.drop('tcp.flags', axis=1)\n",
        "if 'tcp.flags' in X_test.columns:\n",
        "    X_test = X_test.drop('tcp.flags', axis=1)\n",
        "\n",
        "\n",
        "# Entrenamiento: El modelo aprende de los datos escalados (X_train).\n",
        "print(\"Iniciando entrenamiento del modelo...\")\n",
        "model.fit(X_train, y_train)\n",
        "print(\"✅ Modelo entrenado con éxito.\")\n",
        "\n",
        "# El modelo 'model' ahora está listo para hacer predicciones."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9FM2TNvn3ye",
        "outputId": "1bec9498-a4bd-4925-e2b7-cf721b3143c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iniciando entrenamiento del modelo...\n",
            "✅ Modelo entrenado con éxito.\n"
          ]
        }
      ]
    }
  ]
}